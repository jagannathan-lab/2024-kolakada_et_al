---
title: "RandomForest_clean"
author: "Divya Kolakada and Marcin Sajek"
date: "2024-03-13"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Random Forest Classifier for MPRA data

This document contains the code used to create a random forest classifier for the MPRA data for both the EJC-independent and EJC-enhanced reporter cell lines. 

Within the code, "ART" refers to the EJC-independent data and "ARTi" refers to the EJC-enhanced data. AA1 refers to the amino acid in the -2 position to the premature termination codon (PTC) and AA2 refers to the amino acid in the -1 position to the PTC, likewise for Codon1 and Codon2. 

## Preparing The Data 

```{r echo = TRUE}
library(tidyverse)
library(magrittr)
library(randomForest)
library(caret)
library(caTools)
library(matrixStats)
library(pROC)
library(ggthemes)
library(ggpubr)

# Import the ART and ARTi DESeq data frames into environment
d<- read_csv('DESeq_RNA_ART.csv') # ART data frame 

di<- read_csv('DESeq_RNA_ARTi.csv') # ARTi data frame 

# Data was prepared and random forest classifier was created with the same code applied to either the ART or the ARTi data set. 

d <- DESeq_RNA_ART %>% filter(StopCodon != "TGG") # filter out all sequences with TGG at the position of the stop codon in the ART data set 

# Adding properties that may classify low NMD v. high NMD of sequences tested 

# CT and GC percent 
ct <- c("C", "T") # defining a list with C and T
gc <-  c("G", "C") # defining a list with G and C

d$ct_percent <- sapply(d$Sequence, function(text) {
  ctcount <- (sum(
    sapply(ct, 
           function(char) {nchar(gsub(paste0("[^", char, "]"), "", text))}
           )
) /10)*100
  }) # calculating ct percent for each sequence within the data set

d$gc_percent <- sapply(d$Sequence, function(text) {
  gccount <- (sum(
    sapply(gc, 
           function(char) {nchar(gsub(paste0("[^", char, "]"), "", text))}
           )
)/10)*100
  }) # calculating gc percent for each sequence within the data set

# Import files containing codon properties, tRNA-peptide hydrolysis rates, and physical properties of amino acids 
codonproperties<- read_csv('codonproperties.csv') # contains codon usage frequency (GenScript) and tRNA binding strength (Grosjean & Westhof, 2016)

csc_bazzini<- read_csv('csc_bazzini.csv') # contains codon optimality (Bazzini et al., 2016)

PepHydRate<- read_csv('PepHydRate.csv') # contains peptidyl-tRNA hydrolysis rates (Pierson et al., 2016)

aa_phyprop<- read_csv('aa_phyprop.csv') # contains physical properties of amino acids (ThermoFisher)

codonproperties<- merge(codonproperties, csc_bazzini, by="Codon") # merging all codon properties into one data frame

PepHydRate <- PepHydRate[,c(1:5)] # selecting only desired columns in peptidyl-tRNA hydrolysis rate data frame

d_all<- left_join(d, aa_phyprop, by = c("AA1"="Amino Acid")) # adding amino acid physical properties for the amino acid -2 to the PTC

labels <- c("Hydropathy", "Charge", "pKaNH2", "pKaCOOH", "pKR", "Solubility") # labels for the corresponding columns

colnames(d_all)[16:21] <- paste0(labels, "_AA1") # adjusting column names for clarity 

d_all<- left_join(d_all, aa_phyprop, by = c("AA2"="Amino Acid")) # adding amino acid physical properties for the amino acid -1 to the PTC

colnames(d_all)[22:27] <- paste0(labels, "_AA2") # adjusting column names for clarity 

d_all<- left_join(d_all, codonproperties, by = c("Codon1"="Codon")) # adding amino acid physical properties for the codon -2 to the PTC

labels_codon<- c("AA", "Frequency.1000", "tRNA binding", "CSC_293T") # labels for the corresponding columns

colnames(d_all)[28:31] <- paste0(labels_codon, "_C1") # adjusting column names for clarity

d_all<- left_join(d_all, codonproperties, by = c("Codon2"="Codon")) # adding amino acid physical properties for the codon -1 to the PTC

colnames(d_all)[32:35] <- paste0(labels_codon, "_C2") # labels for the corresponding columns

d_all<- left_join(d_all, PepHydRate, by=("AA2")) # adding peptidyl-tRNA hydrolysis rater based on identity of amino acid -1 to the PTC

# Preparing the data frame for the random forest classifier 
d_all<- d_all %>% select(-c("AA_C1", "AA_C2", 
                            "baseMean", "lfcSE", "stat", "pvalue", "padj",
                            )) # selecting out unnecessary columns 

d_all <- d_all %>% arrange(log2FoldChange) # arrange data frame in ascending order of log2FC i.e. highest NMD to lowest NMD)

d_highnmd<- d_all[1:3000,] # select 3000 sequences having the highest NMD activity
d_highnmd$NMD<- "high nmd" # add column indicating that these sequences have high NMD activity

d_nmdesc <- tail(d_all, 3000) # select 3000 sequences having the lowest NMD activity
d_nmdesc$NMD <- "low nmd" # add column indicating that these sequences have low NMD activity

d_art_forest<- rbind(d_highnmd, d_nmdesc) # create a single data frame containing sequences with low and high NMD activity

write_csv(d_art_forest, "art_rf.csv") # write a csv file for easy access

```

## Random Forest Classifier

```{r echo=TRUE}
#Import file for random forest classifier
df <- read_csv('art_rf.csv')

df_filtered <- df %>%
  dplyr::select(-c(1,2)) %>% # removing sequence as every record has different sequence and log2FC as the classification is based on this value
  mutate(Solubility_AA1 = as.numeric(Solubility_AA1),
         Solubility_AA2 = as.numeric(Solubility_AA2)) # changing non-numeric values is numeric columns to NA

nearZeroVar(df_filtered, saveMetrics = TRUE) # test for features with near zero variance, no features with near zero variance

na_vals <- data.frame(matrix(nrow = 0, ncol = 3))

for (i in seq_along(df_filtered)) {
  tmp = data.frame(col = colnames(df_filtered)[i],
                   no_na = table(is.na(df_filtered[,i]))[1],
                   na = table(is.na(df_filtered[,i]))[2])
  na_vals <- rbind(na_vals, tmp)
} # Determining ratio of NA vals to no NA vals 

na_vals <- na_vals %>%
  replace(is.na(.), 0) # pkR features have more NAs than values, may be confusing for classifier

df_filtered <- df_filtered %>%
  dplyr::select(-c(starts_with('pkR'))) %>% # removing pkR values
  mutate_if(is.numeric , replace_na, replace = 0) %>% # replace NA with 0 in numeric columns
  mutate_if(is.character , replace_na, replace = 'None') # replace NA in categorical features as 'None' string

tmp_num <- df_filtered %>%
  select_if(., is.numeric) # subdataframe with numeric features

base_cor <- cor(tmp_num)
# pkA values from carboxy and amino groups are highly correlated, thus keeping only the carboxy values
# The RF and log RF values are also highly correlated, thus keeping only the log RF values

df_filtered_final <- df_filtered %>%
  dplyr::select(-c(starts_with('pKaN'))) %>% # removing the amino group values
  dplyr::select(-c(starts_with('RF'))) %>% # removing RF1 and RF2 values
  dplyr::select(c(ncol(.), 1:(ncol(.)-1))) %>%
  mutate_if(is.character, as.factor) # all categorical vars have to be transformed to factors

set.seed(109) # setting random seed

split <- sample.split(df_filtered_final$NMD, SplitRatio = 0.8) # splitting to train and test (validation) set (80% for training, 20% for testing)

train <- as.data.frame(subset(df_filtered_final, split == "TRUE"))

test <- as.data.frame(subset(df_filtered_final, split == "FALSE"))

trControl <- trainControl(method = "cv", # setting 5x train-test cross validation in training set 
                          number = 5,
                          search = "grid")

# Hyperparameters tuning - adjusting 3 hyperparameters: mtry, maxnode number and tree number
tuneGrid <- expand.grid(.mtry = c(1:10)) 

rf_mtry <- train(NMD~.,
                 data = train,
                 method = "rf",
                 metric = "Accuracy",
                 tuneGrid = tuneGrid,
                 trControl = trControl,
                 importance = TRUE,
                 nodesize = 14,
                 ntree = 300)

best_mtry <- rf_mtry$bestTune$mtry

store_maxnode <- list()

tuneGrid <- expand.grid(.mtry = best_mtry)

for (maxnodes in c(5:30)) {
  set.seed(109)
  rf_maxnode <- train(NMD~.,
                      data = train,
                      method = "rf",
                      metric = "Accuracy",
                      tuneGrid = tuneGrid,
                      trControl = trControl,
                      importance = TRUE,
                      nodesize = 14,
                      maxnodes = maxnodes,
                      ntree = 300)
  current_iteration <- toString(maxnodes)
  store_maxnode[[current_iteration]] <- rf_maxnode
}

results_mtry <- resamples(store_maxnode)

maxnode <- results_mtry$values %>%
  dplyr::select(grep('Accuracy', colnames(.))) %>%
  as.matrix() %>%
  colMedians(.)

best_maxnode <- which(maxnode == max(maxnode))[1]                

tree_n <- c(250, 300, 350, 400, 450, 500, 550, 600, 800, 1000, 2000)

store_maxtrees <- list()

for (ntree in c(250, 300, 350, 400, 450, 500, 550, 600, 800, 1000, 2000)) {
  set.seed(109)
  rf_maxtrees <- train(NMD~.,
                       data = train,
                       method = "rf",
                       metric = "Accuracy",
                       tuneGrid = tuneGrid,
                       trControl = trControl,
                       importance = TRUE,
                       nodesize = 14,
                       maxnodes = best_maxnode,
                       ntree = ntree)
  key <- toString(ntree)
  store_maxtrees[[key]] <- rf_maxtrees
}

results_tree <- resamples(store_maxtrees)

tree <- results_tree$values %>%
  dplyr::select(grep('Accuracy', colnames(.))) %>%
  as.matrix() %>%
  colMedians(.)

best_tree <- tree_n[which(tree == max(tree))[1]]

# Training classifier with previously optimized hyperparameters
fit_rf <- train(NMD~.,
                train,
                method = "rf",
                metric = "Accuracy",
                tuneGrid = tuneGrid,
                trControl = trControl,
                importance = TRUE,
                nodesize = 14,
                ntree = best_tree,
                maxnodes = best_maxnode)

saveRDS(fit_rf, file = 'rf_model_art.Rds')

# Prediction on test (validation) dataset
pred <- predict(fit_rf, test, type = 'prob', norm.votes = TRUE) # prediction with tree votes

pred_raw <- predict(fit_rf, test) # binary classification only

conf_mtx <- confusionMatrix(pred_raw, test$NMD, mode = 'everything') # confusion matrix

conf_mtx$table %>% 
  as_tibble() %>%
  write_csv('confusion_matrix_arti_noRF.csv') # save confusion matrix data as csv 

conf_mtx$byClass %>%
  enframe() %>%
  write_csv('performance_arti_noRF.csv', col_names = FALSE) # save model performance as csv

importance <- varImp(fit_rf, useModel = TRUE) # feature importance

importance_df <- importance$importance %>%
  arrange(desc(`nmd escape`)) %>%
  dplyr::select(-c(2)) %>%
  rownames_to_column('feature') %>%
  dplyr::rename('importance' = 'nmd escape')

write_csv(importance_df, 'feature_importance_arti_noRF.csv') # save features of importance as csv

# Calculating receiver operating characteristic (ROC) curves. 
ROC_rf <- roc(test$NMD, pred[,2])

saveRDS(ROC_rf, file = "ROC_rf_art.rds") # saving the results for easy access

# Repeated ROC calculation for ARTi in the same way 

ROC_rf_art<- readRDS("ROC_rf_art.rds") # loading the r object ART

ROC_rf_art<- readRDS("ROC_rf_arti.rds") # loading the r object ARTi

ggroc(list(art = ROC_rf_art, arti = ROC_rf_arti), legacy.axes = TRUE) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "black") +
  labs(title = "ROC Curves for ART and ARTi") +
  theme_classic() # plotting ROC curves for both ART and ARTi on the same plot 

# Plotting features of importance 
feature_importance_art_withRF <- read_csv("feature_importance_art_withRF.csv")

feature_art<- ggplot(feature_importance_art_withRF[1:12,], aes(x = importance, y = reorder(feature, +importance))) +
  geom_bar(stat = "identity", fill = "#9f9f9f") +
  labs(x = "Importance", y = "Feature")

```

## Further Examining Features Of Importance

Focusing on the the two most important predictors of the EJC-independent model 

```{r}
#RF1 and RF2 peptidyl-tRNA hydrolysis rates
d_pep<- left_join(d, PepHydRate, by=("AA2")) # add peptidyl-tRNA hydrolysis rates to the DESeq ART dataset

# RF1 tRNA-peptidyl hydrolysis rates 
colnames(d_pep)[colnames(d_pep) == "log(RF1 rate)"] <- "lgrf1"

d_pep_fast<- subset(d_pep, lgrf1>1) # define threshold for fast RF1 hydrolysis rates 

d_pep_slow<- subset(d_pep, lgrf1<= -0.5) # define threshold for slow RF1 hydrolysis rates

d_pep_rf1 <- ggplot()+
  geom_histogram(data=d_pep, aes(x = log2FoldChange, y=..count..), fill ="grey", alpha = 1, binwidth = 0.1)+
  geom_density(data=d_pep_fast, aes(x = log2FoldChange, y=..count..), color = "#0020B7", adjust = 2)+
  geom_density(data=d_pep_slow, aes(x = log2FoldChange, y=..count..), color = "#CD3E34", adjust = 2)+
  theme_classic()+
  ggtitle("PepHydRate_RF1") # density plot for hydrolysis rates  

# Wilcoxon test to determine whether the fast and slow population separation is significant (RF1)
d_pep_fast$pepcat<- "Fast"

d_pep_slow$pepcat<- "Slow"

y<- rbind(d_pep_fast, d_pep_slow)

wilcox.test(y$log2FoldChange ~ y$pepcat)

# RF2 tRNA-peptidyl hydrolysis rates 
colnames(d_pep)[colnames(d_pep) == "log(RF2 rate)"] <- "lgrf2"

d_pep_fast_r2<- subset(d_pep, lgrf2>1.25) # define threshold for fast RF2 hydrolysis rates

d_pep_slow_r2<- subset(d_pep, lgrf2<= 0) # define threshold for slow RF2 hydrolysis rates

d_pep_rf2 <- ggplot()+
  geom_histogram(data=d_pep, aes(x = log2FoldChange), fill ="grey", alpha = 1, binwidth = 0.1)+
  geom_density(data=d_pep_fast_r2, aes(x = log2FoldChange, y=..count..), color = "#0020B7", adjust = 2)+
  geom_density(data=d_pep_slow_r2, aes(x = log2FoldChange, y=..count..), color = "#CD3E34", adjust = 2)+
  theme_classic()+
  ggtitle("PepHydRate_RF2") # density plot for hydrolysis rates

# Wilcoxon test to determine whether the fast and slow population separation is significant (RF2)
d_pep_fast_r2$pepcat<- "Fast"

d_pep_slow_r2$pepcat<- "Slow"

z<- rbind(d_pep_fast_r2, d_pep_slow_r2)

wilcox.test(z$log2FoldChange ~ z$pepcat)

```
